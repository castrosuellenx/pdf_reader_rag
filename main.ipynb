{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2dd443d-60c9-4eea-8461-61ca204d4847",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5f47ab-ffba-4afa-8e41-5cbb953cbb09",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb52d55-ce84-4b59-82cf-1811f912ded8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:44:51.021714Z",
     "start_time": "2024-09-12T21:44:50.999262Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load dos modelos (Embeddings e LLM)\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(model_name= \"gpt-4o-mini\", max_tokens = 50, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266e50b6-e28c-40fa-85b6-26b394229757",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:44:56.411563Z",
     "start_time": "2024-09-12T21:44:56.380347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages: 3\n"
     ]
    }
   ],
   "source": [
    "# Carregar o PDF\n",
    "\n",
    "pdf_link = \"assets/teste.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_link, extract_images=False)\n",
    "pages = loader.load_and_split()\n",
    "pages = loader.load()\n",
    "\n",
    "print(f\"Pages: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52c3012-a401-41b0-80f6-6a66e8ec72ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:44:58.301727Z",
     "start_time": "2024-09-12T21:44:58.284869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: 21\n"
     ]
    }
   ],
   "source": [
    "#Separar em Chunks (Pedaços de documento)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=40,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(f\"Chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e020339-5898-4bb8-b705-d1e2ad67c50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:44:59.477976Z",
     "start_time": "2024-09-12T21:44:59.474219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Path do DB\n",
    "CHROMA_PATH = \"generated_vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1055bc7e-b9b1-46b9-9204-f6ea1e0b3fbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T21:44:59.897154Z",
     "start_time": "2024-09-12T21:44:59.872918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvar no Vector DB - Chroma\n",
    "db = Chroma.from_documents(chunks, embedding=embeddings_model, persist_directory=CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59982feea178488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar DB\n",
    "vector_db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings_model)\n",
    "\n",
    "# Load Retriever\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56241f99-2650-443c-aeae-fdba9e2e3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions about documents, based on the context: \\n\\n{context}\"),\n",
    "    (\"user\", \"Please answer the question: {question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b0eeef-986b-410f-af26-a1089ea2bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um question-answering chain\n",
    "chain = create_stuff_documents_chain(llm, prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2c2ea8-c7e1-4ce4-bba9-9cd04f493e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma função que recebe os chunks mais relevantes (context) e a pergunta do usuário, retorna a resposta da llm\n",
    "def ask(question):\n",
    "    context = retriever.invoke(question)\n",
    "    answer = chain.invoke({\"context\": context, \"question\": question})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c4c616-9874-48ff-b2e0-3bb892c43836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digite sua pergunta relacionada ao documento:  Qual é o titulo do documento?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta:  O título do documento é \"Proposições legislativas\".\n"
     ]
    }
   ],
   "source": [
    "# Responde o usuário\n",
    "user_question = input(\"Digite sua pergunta relacionada ao documento: \")\n",
    "answer = ask(user_question)\n",
    "print(\"\\nResposta: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992a903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
